{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Document to Graph\n",
    "- using neo4j knowledge graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Document Objects\n",
    "- prepare data for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to extract text from a folder of .docx files\n",
    "import os\n",
    "from spire.doc import Document\n",
    "\n",
    "# Function Definition\n",
    "def extract_text_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Extracts text from all .docx files in a folder and stores them in a list.\n",
    "    Removes first line of text from each document to remove warning or metadata lines\n",
    "    from Spire.Doc that is not part of the actual document content.\n",
    "\n",
    "    Args:\n",
    "    folder_path (str): The path to the folder containing the .docx files.\n",
    "\n",
    "    Returns:\n",
    "    list: A list containing the extracted text from each document.\n",
    "    \"\"\"\n",
    "    documents_text = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".docx\"):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            document = Document()\n",
    "            document.LoadFromFile(filepath)\n",
    "            # Extract text and remove the first line (if it exists)\n",
    "            text = document.GetText()\n",
    "            lines = text.splitlines(keepends=True)  # Split by lines, keeping newlines\n",
    "            if lines:  # Check if there are any lines\n",
    "                text_without_first_line = \"\".join(lines[1:])  # Join lines from index 1 onwards\n",
    "            else:\n",
    "                text_without_first_line = \"\"  # Empty string if no lines\n",
    "\n",
    "            documents_text.append(text_without_first_line)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "    return documents_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function on \"Documents\" folder\n",
    "folder_path = os.getenv(\"DOC_FILEPATH\")\n",
    "documents_text = extract_text_from_folder(folder_path)\n",
    "\n",
    "# Print the extracted text\n",
    "# print(documents_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# for each document in documents_text, create a Document object for it and add it to a list called document_objects\n",
    "document_objects = []\n",
    "for text in documents_text:\n",
    "    document = Document(page_content=text)\n",
    "    document_objects.append(document)\n",
    "\n",
    "# print the first document object in the list\n",
    "# print(document_objects[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Main Body Text and Parse to Knowledge Graph\n",
    "- will be done for each document\n",
    "- invoking llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "neo4j_uri = os.getenv(\"NEO4J_URI\")\n",
    "neo4j_username = os.getenv(\"NEO4J_USERNAME\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "os.environ[\"NEO4J_URI\"] = neo4j_uri\n",
    "os.environ[\"NEO4J_USERNAME\"] = neo4j_username\n",
    "os.environ[\"NEO4J_PASSWORD\"] = neo4j_password\n",
    "    \n",
    "graph = Neo4jGraph()\n",
    "\n",
    "# Create LLMGraphTransformer with GPT-3.5 model\n",
    "# llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")  ## uncomment this line to use GPT-3.5 model\n",
    "\n",
    "# Create LLMGraphTransformer with GPT-4 model\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\") ## uncomment this line to use GPT-4 model\n",
    "\n",
    "# Initilise graph transformer\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "# Define constants for chunking\n",
    "CHUNK_SIZE = 512\n",
    "CHUNK_OVERLAP = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# clean the text, remove \\n and \\r\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\r\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def generate_body_text(text, llm):\n",
    "    prompt = f\"\"\"\n",
    "        You will be given text extracted from trip reports from Word documents.\n",
    "        The text will contain the main body content, as well as irrelevant section's random metadata, and whitespace characters like \\n, \\r, \\t. \n",
    "        Your task is to extract only the relevant body text from the reports, together with its document title and reporting officer, excluding all other irrelevant information.\n",
    "        To guide you, the reports are typically:\n",
    "        - written in paragraph form, with 7 chapters regarding the trip and the city visited\n",
    "        - includes the document title, city & year visited at the beginning of the report and staffing officer at the end\n",
    "        - includes names of politicians and initiatives organised by the local government, which are relevant\n",
    "        - includes innovations and impacts of initiatives, challenges faced, which are relevant\n",
    "        - main body content is generally written in full sentences and are relevant\n",
    "        Please output relevant body text bound by each chapter, with the corresponding city, year visited and officer, without any additional formatting or comments.\n",
    "\n",
    "        Extracted document Text:\n",
    "        {text}\n",
    "        \"\"\"\n",
    "\n",
    "    # Invoke the LLM model to extract the relevant text\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    return clean_text(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "# # Create a function that iterates through the list of document objects and generates the body text for each document, rewriting over the page_content attribute\n",
    "# # Uncomment if processing multiple documents at once\n",
    "# def generate_documents(documents, llm):\n",
    "#     \"\"\"\n",
    "#     Iterates through the list of document objects and generates the body text for each document, rewriting over the page_content attribute.\n",
    "\n",
    "#     Args:\n",
    "#     documents (list): A list of document objects.\n",
    "#     llm (ChatOpenAI): A ChatOpenAI object.\n",
    "\n",
    "#     Returns:\n",
    "#     list: A list of document objects with the page_content attribute rewritten to contain the generated body text.\n",
    "#     \"\"\"\n",
    "#     for document in documents:\n",
    "#         document.page_content = generate_body_text(document.page_content, llm)\n",
    "#     return documents\n",
    "\n",
    "\n",
    "# Create a process and store document function that combines the above functions and stores the processed documents in the graph\n",
    "def process_and_store_documents(documents, llm, llm_transformer, graph):\n",
    "    \"\"\"\n",
    "    Processes the documents by generating the body text and splitting the documents, then stores the processed documents in the graph.\n",
    "\n",
    "    Args:\n",
    "    documents (list): A document object.\n",
    "    llm (ChatOpenAI): A ChatOpenAI LLM object.\n",
    "    llm_transformer (LLMGraphTransformer): An LLMGraphTransformer object.\n",
    "    graph (Neo4jGraph): A Neo4jGraph object.\n",
    "    \"\"\"\n",
    "    # Generate the body text for document\n",
    "    body_text = generate_body_text(documents.page_content, llm)\n",
    "\n",
    "    # Split the documents into chunks\n",
    "    text_splitter = TokenTextSplitter(chunk_size = CHUNK_SIZE, chunk_overlap = CHUNK_OVERLAP)\n",
    "    split_text = text_splitter.split_text(body_text)\n",
    "    doc = [Document(page_content=text) for text in split_text]\n",
    "\n",
    "    # print(doc[0].page_content)\n",
    "\n",
    "    # Convert the split documents to graph documents and add to graph\n",
    "    graph_docs = llm_transformer.convert_to_graph_documents(doc)\n",
    "    graph.add_graph_documents(\n",
    "        graph_docs,\n",
    "        baseEntityLabel=True,\n",
    "        include_source=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the required functions on the document_objects list\n",
    "# iterate through the list and process each document\n",
    "for document in document_objects:\n",
    "    process_and_store_documents(document, llm, llm_transformer, graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge graph looks good. Concept is working well. Can move on to querying"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
